{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploy on the web.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VectorBw/Data-science/blob/master/Deploy_on_the_web.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge7xizIEd4gH",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 3 - Deploy a neural network in a web site\n",
        "\n",
        "We will create a simple tool that recognizes drawings and outputs the names of the current drawing. This app will run directly on the browser without any installations. We will use Google Colab for training the model, and we will deploy it on the browser using TensorFlow.js.\n",
        "\n",
        "This assignment is heavily inspired from [this article](https://medium.com/tensorflow/train-on-google-colab-and-run-on-the-browser-a-case-study-8a45f9b1474e).\n",
        "As always, we analyse it:\n",
        "- there is an obvious improvement: we can solve the problem of memory exhaustion. There are at least 2 solutions:\n",
        "    - Instead of loading all the images in memory (which is quite stupid, because it requires a lot of memory !!), we could use Keras' [ImageDataGenerator](https://keras.io/preprocessing/image/) and its function flow_from_directory() to load only the few images required for each iteration of the learning process. But if we did that, we would face another problem: the training would become very slow, because each individual file would be fetched from disk.\n",
        "    - Or simply load small parts of the dataset in memory, train the network on this part, load another small part, improve the training, and so on... In this notebook, we take that solution.\n",
        "- that problem being solved, we can use the full dataset of 345 classes, not only a subset of 100 of them. The drawback, as you will see, is that many drawings are unclear, and some classes can easily be mixed with other ones. Therefore, the accuracy won't be better than 70%.\n",
        "\n",
        "Moreover, we deploy the website directly from Colaboratory. No need for anything else, which is much easier than in the article.\n",
        "\n",
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/800/1*Xbvo-Diilbltp3AEgtTOig.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDmtFysceh5Y",
        "colab_type": "text"
      },
      "source": [
        "##Download the dataset\n",
        "We will use a CNN to recognize drawings of different types. The CNN will be trained on the [Quick Draw dataset](https://github.com/googlecreativelab/quickdraw-dataset). The dataset contains around 50 million drawings of 345 classes.\n",
        "\n",
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/800/1*kMEmKip2dqTQPX4m9Nt8gQ.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4Pvl-cYgL0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIRECTORY = \"data\"\n",
        "\n",
        "!mkdir {DATA_DIRECTORY}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3f_wO0UiGIZ",
        "colab_type": "text"
      },
      "source": [
        "First we download the dataset from Google Cloud Storage. It is opensourced by Google; we simply have to follow the [instructions](https://cloud.google.com/storage/docs/access-public-data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSnjS7fCjXw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save the names of the files that we want to download, into a file called list_files.txt\n",
        "!gsutil ls -r gs://quickdraw_dataset/full/numpy_bitmap > list_files.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SV6W4KykqLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the list in memory\n",
        "with open(\"list_files.txt\",\"r\") as mini_classes:  \n",
        "  classes = mini_classes.readlines() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJG-EK_ZlLoL",
        "colab_type": "code",
        "outputId": "1412aebf-9c3a-46d0-aada-554d3a7fb4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5846
        }
      },
      "source": [
        "# The file names are like 'gs://quickdraw_dataset/full/numpy_bitmap/The Eiffel Tower.npy\\n' , \n",
        "# but we want to keep only 'The Eiffel Tower', so we need to suppress the other caracters\n",
        "#classes = # YOUR CODE HERE\n",
        "for i in range(len(classes)):\n",
        "  classes[i] = classes[i].replace(\"gs://quickdraw_dataset/full/numpy_bitmap/\",\"\")\n",
        "  classes[i] = classes[i].replace(\".npy\\n\",\"\")\n",
        "  print(classes[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ":\n",
            "\n",
            "The Eiffel Tower\n",
            "The Great Wall of China\n",
            "The Mona Lisa\n",
            "aircraft carrier\n",
            "airplane\n",
            "alarm clock\n",
            "ambulance\n",
            "angel\n",
            "animal migration\n",
            "ant\n",
            "anvil\n",
            "apple\n",
            "arm\n",
            "asparagus\n",
            "axe\n",
            "backpack\n",
            "banana\n",
            "bandage\n",
            "barn\n",
            "baseball bat\n",
            "baseball\n",
            "basket\n",
            "basketball\n",
            "bat\n",
            "bathtub\n",
            "beach\n",
            "bear\n",
            "beard\n",
            "bed\n",
            "bee\n",
            "belt\n",
            "bench\n",
            "bicycle\n",
            "binoculars\n",
            "bird\n",
            "birthday cake\n",
            "blackberry\n",
            "blueberry\n",
            "book\n",
            "boomerang\n",
            "bottlecap\n",
            "bowtie\n",
            "bracelet\n",
            "brain\n",
            "bread\n",
            "bridge\n",
            "broccoli\n",
            "broom\n",
            "bucket\n",
            "bulldozer\n",
            "bus\n",
            "bush\n",
            "butterfly\n",
            "cactus\n",
            "cake\n",
            "calculator\n",
            "calendar\n",
            "camel\n",
            "camera\n",
            "camouflage\n",
            "campfire\n",
            "candle\n",
            "cannon\n",
            "canoe\n",
            "car\n",
            "carrot\n",
            "castle\n",
            "cat\n",
            "ceiling fan\n",
            "cell phone\n",
            "cello\n",
            "chair\n",
            "chandelier\n",
            "church\n",
            "circle\n",
            "clarinet\n",
            "clock\n",
            "cloud\n",
            "coffee cup\n",
            "compass\n",
            "computer\n",
            "cookie\n",
            "cooler\n",
            "couch\n",
            "cow\n",
            "crab\n",
            "crayon\n",
            "crocodile\n",
            "crown\n",
            "cruise ship\n",
            "cup\n",
            "diamond\n",
            "dishwasher\n",
            "diving board\n",
            "dog\n",
            "dolphin\n",
            "donut\n",
            "door\n",
            "dragon\n",
            "dresser\n",
            "drill\n",
            "drums\n",
            "duck\n",
            "dumbbell\n",
            "ear\n",
            "elbow\n",
            "elephant\n",
            "envelope\n",
            "eraser\n",
            "eye\n",
            "eyeglasses\n",
            "face\n",
            "fan\n",
            "feather\n",
            "fence\n",
            "finger\n",
            "fire hydrant\n",
            "fireplace\n",
            "firetruck\n",
            "fish\n",
            "flamingo\n",
            "flashlight\n",
            "flip flops\n",
            "floor lamp\n",
            "flower\n",
            "flying saucer\n",
            "foot\n",
            "fork\n",
            "frog\n",
            "frying pan\n",
            "garden hose\n",
            "garden\n",
            "giraffe\n",
            "goatee\n",
            "golf club\n",
            "grapes\n",
            "grass\n",
            "guitar\n",
            "hamburger\n",
            "hammer\n",
            "hand\n",
            "harp\n",
            "hat\n",
            "headphones\n",
            "hedgehog\n",
            "helicopter\n",
            "helmet\n",
            "hexagon\n",
            "hockey puck\n",
            "hockey stick\n",
            "horse\n",
            "hospital\n",
            "hot air balloon\n",
            "hot dog\n",
            "hot tub\n",
            "hourglass\n",
            "house plant\n",
            "house\n",
            "hurricane\n",
            "ice cream\n",
            "jacket\n",
            "jail\n",
            "kangaroo\n",
            "key\n",
            "keyboard\n",
            "knee\n",
            "knife\n",
            "ladder\n",
            "lantern\n",
            "laptop\n",
            "leaf\n",
            "leg\n",
            "light bulb\n",
            "lighter\n",
            "lighthouse\n",
            "lightning\n",
            "line\n",
            "lion\n",
            "lipstick\n",
            "lobster\n",
            "lollipop\n",
            "mailbox\n",
            "map\n",
            "marker\n",
            "matches\n",
            "megaphone\n",
            "mermaid\n",
            "microphone\n",
            "microwave\n",
            "monkey\n",
            "moon\n",
            "mosquito\n",
            "motorbike\n",
            "mountain\n",
            "mouse\n",
            "moustache\n",
            "mouth\n",
            "mug\n",
            "mushroom\n",
            "nail\n",
            "necklace\n",
            "nose\n",
            "ocean\n",
            "octagon\n",
            "octopus\n",
            "onion\n",
            "oven\n",
            "owl\n",
            "paint can\n",
            "paintbrush\n",
            "palm tree\n",
            "panda\n",
            "pants\n",
            "paper clip\n",
            "parachute\n",
            "parrot\n",
            "passport\n",
            "peanut\n",
            "pear\n",
            "peas\n",
            "pencil\n",
            "penguin\n",
            "piano\n",
            "pickup truck\n",
            "picture frame\n",
            "pig\n",
            "pillow\n",
            "pineapple\n",
            "pizza\n",
            "pliers\n",
            "police car\n",
            "pond\n",
            "pool\n",
            "popsicle\n",
            "postcard\n",
            "potato\n",
            "power outlet\n",
            "purse\n",
            "rabbit\n",
            "raccoon\n",
            "radio\n",
            "rain\n",
            "rainbow\n",
            "rake\n",
            "remote control\n",
            "rhinoceros\n",
            "rifle\n",
            "river\n",
            "roller coaster\n",
            "rollerskates\n",
            "sailboat\n",
            "sandwich\n",
            "saw\n",
            "saxophone\n",
            "school bus\n",
            "scissors\n",
            "scorpion\n",
            "screwdriver\n",
            "sea turtle\n",
            "see saw\n",
            "shark\n",
            "sheep\n",
            "shoe\n",
            "shorts\n",
            "shovel\n",
            "sink\n",
            "skateboard\n",
            "skull\n",
            "skyscraper\n",
            "sleeping bag\n",
            "smiley face\n",
            "snail\n",
            "snake\n",
            "snorkel\n",
            "snowflake\n",
            "snowman\n",
            "soccer ball\n",
            "sock\n",
            "speedboat\n",
            "spider\n",
            "spoon\n",
            "spreadsheet\n",
            "square\n",
            "squiggle\n",
            "squirrel\n",
            "stairs\n",
            "star\n",
            "steak\n",
            "stereo\n",
            "stethoscope\n",
            "stitches\n",
            "stop sign\n",
            "stove\n",
            "strawberry\n",
            "streetlight\n",
            "string bean\n",
            "submarine\n",
            "suitcase\n",
            "sun\n",
            "swan\n",
            "sweater\n",
            "swing set\n",
            "sword\n",
            "syringe\n",
            "t-shirt\n",
            "table\n",
            "teapot\n",
            "teddy-bear\n",
            "telephone\n",
            "television\n",
            "tennis racquet\n",
            "tent\n",
            "tiger\n",
            "toaster\n",
            "toe\n",
            "toilet\n",
            "tooth\n",
            "toothbrush\n",
            "toothpaste\n",
            "tornado\n",
            "tractor\n",
            "traffic light\n",
            "train\n",
            "tree\n",
            "triangle\n",
            "trombone\n",
            "truck\n",
            "trumpet\n",
            "umbrella\n",
            "underwear\n",
            "van\n",
            "vase\n",
            "violin\n",
            "washing machine\n",
            "watermelon\n",
            "waterslide\n",
            "whale\n",
            "wheel\n",
            "windmill\n",
            "wine bottle\n",
            "wine glass\n",
            "wristwatch\n",
            "yoga\n",
            "zebra\n",
            "zigzag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STSR3vA8QoFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes.remove(\":\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4qw-HXSQ7Gx",
        "colab_type": "code",
        "outputId": "f2c81e24-e0f1-4ac6-c6ae-a6b7b5b6e5f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5813
        }
      },
      "source": [
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Eiffel Tower',\n",
              " 'The Great Wall of China',\n",
              " 'The Mona Lisa',\n",
              " 'aircraft carrier',\n",
              " 'airplane',\n",
              " 'alarm clock',\n",
              " 'ambulance',\n",
              " 'angel',\n",
              " 'animal migration',\n",
              " 'ant',\n",
              " 'anvil',\n",
              " 'apple',\n",
              " 'arm',\n",
              " 'asparagus',\n",
              " 'axe',\n",
              " 'backpack',\n",
              " 'banana',\n",
              " 'bandage',\n",
              " 'barn',\n",
              " 'baseball bat',\n",
              " 'baseball',\n",
              " 'basket',\n",
              " 'basketball',\n",
              " 'bat',\n",
              " 'bathtub',\n",
              " 'beach',\n",
              " 'bear',\n",
              " 'beard',\n",
              " 'bed',\n",
              " 'bee',\n",
              " 'belt',\n",
              " 'bench',\n",
              " 'bicycle',\n",
              " 'binoculars',\n",
              " 'bird',\n",
              " 'birthday cake',\n",
              " 'blackberry',\n",
              " 'blueberry',\n",
              " 'book',\n",
              " 'boomerang',\n",
              " 'bottlecap',\n",
              " 'bowtie',\n",
              " 'bracelet',\n",
              " 'brain',\n",
              " 'bread',\n",
              " 'bridge',\n",
              " 'broccoli',\n",
              " 'broom',\n",
              " 'bucket',\n",
              " 'bulldozer',\n",
              " 'bus',\n",
              " 'bush',\n",
              " 'butterfly',\n",
              " 'cactus',\n",
              " 'cake',\n",
              " 'calculator',\n",
              " 'calendar',\n",
              " 'camel',\n",
              " 'camera',\n",
              " 'camouflage',\n",
              " 'campfire',\n",
              " 'candle',\n",
              " 'cannon',\n",
              " 'canoe',\n",
              " 'car',\n",
              " 'carrot',\n",
              " 'castle',\n",
              " 'cat',\n",
              " 'ceiling fan',\n",
              " 'cell phone',\n",
              " 'cello',\n",
              " 'chair',\n",
              " 'chandelier',\n",
              " 'church',\n",
              " 'circle',\n",
              " 'clarinet',\n",
              " 'clock',\n",
              " 'cloud',\n",
              " 'coffee cup',\n",
              " 'compass',\n",
              " 'computer',\n",
              " 'cookie',\n",
              " 'cooler',\n",
              " 'couch',\n",
              " 'cow',\n",
              " 'crab',\n",
              " 'crayon',\n",
              " 'crocodile',\n",
              " 'crown',\n",
              " 'cruise ship',\n",
              " 'cup',\n",
              " 'diamond',\n",
              " 'dishwasher',\n",
              " 'diving board',\n",
              " 'dog',\n",
              " 'dolphin',\n",
              " 'donut',\n",
              " 'door',\n",
              " 'dragon',\n",
              " 'dresser',\n",
              " 'drill',\n",
              " 'drums',\n",
              " 'duck',\n",
              " 'dumbbell',\n",
              " 'ear',\n",
              " 'elbow',\n",
              " 'elephant',\n",
              " 'envelope',\n",
              " 'eraser',\n",
              " 'eye',\n",
              " 'eyeglasses',\n",
              " 'face',\n",
              " 'fan',\n",
              " 'feather',\n",
              " 'fence',\n",
              " 'finger',\n",
              " 'fire hydrant',\n",
              " 'fireplace',\n",
              " 'firetruck',\n",
              " 'fish',\n",
              " 'flamingo',\n",
              " 'flashlight',\n",
              " 'flip flops',\n",
              " 'floor lamp',\n",
              " 'flower',\n",
              " 'flying saucer',\n",
              " 'foot',\n",
              " 'fork',\n",
              " 'frog',\n",
              " 'frying pan',\n",
              " 'garden hose',\n",
              " 'garden',\n",
              " 'giraffe',\n",
              " 'goatee',\n",
              " 'golf club',\n",
              " 'grapes',\n",
              " 'grass',\n",
              " 'guitar',\n",
              " 'hamburger',\n",
              " 'hammer',\n",
              " 'hand',\n",
              " 'harp',\n",
              " 'hat',\n",
              " 'headphones',\n",
              " 'hedgehog',\n",
              " 'helicopter',\n",
              " 'helmet',\n",
              " 'hexagon',\n",
              " 'hockey puck',\n",
              " 'hockey stick',\n",
              " 'horse',\n",
              " 'hospital',\n",
              " 'hot air balloon',\n",
              " 'hot dog',\n",
              " 'hot tub',\n",
              " 'hourglass',\n",
              " 'house plant',\n",
              " 'house',\n",
              " 'hurricane',\n",
              " 'ice cream',\n",
              " 'jacket',\n",
              " 'jail',\n",
              " 'kangaroo',\n",
              " 'key',\n",
              " 'keyboard',\n",
              " 'knee',\n",
              " 'knife',\n",
              " 'ladder',\n",
              " 'lantern',\n",
              " 'laptop',\n",
              " 'leaf',\n",
              " 'leg',\n",
              " 'light bulb',\n",
              " 'lighter',\n",
              " 'lighthouse',\n",
              " 'lightning',\n",
              " 'line',\n",
              " 'lion',\n",
              " 'lipstick',\n",
              " 'lobster',\n",
              " 'lollipop',\n",
              " 'mailbox',\n",
              " 'map',\n",
              " 'marker',\n",
              " 'matches',\n",
              " 'megaphone',\n",
              " 'mermaid',\n",
              " 'microphone',\n",
              " 'microwave',\n",
              " 'monkey',\n",
              " 'moon',\n",
              " 'mosquito',\n",
              " 'motorbike',\n",
              " 'mountain',\n",
              " 'mouse',\n",
              " 'moustache',\n",
              " 'mouth',\n",
              " 'mug',\n",
              " 'mushroom',\n",
              " 'nail',\n",
              " 'necklace',\n",
              " 'nose',\n",
              " 'ocean',\n",
              " 'octagon',\n",
              " 'octopus',\n",
              " 'onion',\n",
              " 'oven',\n",
              " 'owl',\n",
              " 'paint can',\n",
              " 'paintbrush',\n",
              " 'palm tree',\n",
              " 'panda',\n",
              " 'pants',\n",
              " 'paper clip',\n",
              " 'parachute',\n",
              " 'parrot',\n",
              " 'passport',\n",
              " 'peanut',\n",
              " 'pear',\n",
              " 'peas',\n",
              " 'pencil',\n",
              " 'penguin',\n",
              " 'piano',\n",
              " 'pickup truck',\n",
              " 'picture frame',\n",
              " 'pig',\n",
              " 'pillow',\n",
              " 'pineapple',\n",
              " 'pizza',\n",
              " 'pliers',\n",
              " 'police car',\n",
              " 'pond',\n",
              " 'pool',\n",
              " 'popsicle',\n",
              " 'postcard',\n",
              " 'potato',\n",
              " 'power outlet',\n",
              " 'purse',\n",
              " 'rabbit',\n",
              " 'raccoon',\n",
              " 'radio',\n",
              " 'rain',\n",
              " 'rainbow',\n",
              " 'rake',\n",
              " 'remote control',\n",
              " 'rhinoceros',\n",
              " 'rifle',\n",
              " 'river',\n",
              " 'roller coaster',\n",
              " 'rollerskates',\n",
              " 'sailboat',\n",
              " 'sandwich',\n",
              " 'saw',\n",
              " 'saxophone',\n",
              " 'school bus',\n",
              " 'scissors',\n",
              " 'scorpion',\n",
              " 'screwdriver',\n",
              " 'sea turtle',\n",
              " 'see saw',\n",
              " 'shark',\n",
              " 'sheep',\n",
              " 'shoe',\n",
              " 'shorts',\n",
              " 'shovel',\n",
              " 'sink',\n",
              " 'skateboard',\n",
              " 'skull',\n",
              " 'skyscraper',\n",
              " 'sleeping bag',\n",
              " 'smiley face',\n",
              " 'snail',\n",
              " 'snake',\n",
              " 'snorkel',\n",
              " 'snowflake',\n",
              " 'snowman',\n",
              " 'soccer ball',\n",
              " 'sock',\n",
              " 'speedboat',\n",
              " 'spider',\n",
              " 'spoon',\n",
              " 'spreadsheet',\n",
              " 'square',\n",
              " 'squiggle',\n",
              " 'squirrel',\n",
              " 'stairs',\n",
              " 'star',\n",
              " 'steak',\n",
              " 'stereo',\n",
              " 'stethoscope',\n",
              " 'stitches',\n",
              " 'stop sign',\n",
              " 'stove',\n",
              " 'strawberry',\n",
              " 'streetlight',\n",
              " 'string bean',\n",
              " 'submarine',\n",
              " 'suitcase',\n",
              " 'sun',\n",
              " 'swan',\n",
              " 'sweater',\n",
              " 'swing set',\n",
              " 'sword',\n",
              " 'syringe',\n",
              " 't-shirt',\n",
              " 'table',\n",
              " 'teapot',\n",
              " 'teddy-bear',\n",
              " 'telephone',\n",
              " 'television',\n",
              " 'tennis racquet',\n",
              " 'tent',\n",
              " 'tiger',\n",
              " 'toaster',\n",
              " 'toe',\n",
              " 'toilet',\n",
              " 'tooth',\n",
              " 'toothbrush',\n",
              " 'toothpaste',\n",
              " 'tornado',\n",
              " 'tractor',\n",
              " 'traffic light',\n",
              " 'train',\n",
              " 'tree',\n",
              " 'triangle',\n",
              " 'trombone',\n",
              " 'truck',\n",
              " 'trumpet',\n",
              " 'umbrella',\n",
              " 'underwear',\n",
              " 'van',\n",
              " 'vase',\n",
              " 'violin',\n",
              " 'washing machine',\n",
              " 'watermelon',\n",
              " 'waterslide',\n",
              " 'whale',\n",
              " 'wheel',\n",
              " 'windmill',\n",
              " 'wine bottle',\n",
              " 'wine glass',\n",
              " 'wristwatch',\n",
              " 'yoga',\n",
              " 'zebra',\n",
              " 'zigzag']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uVzJszeqwz6",
        "colab_type": "code",
        "outputId": "3a5d1ab0-33eb-40f4-b525-296c0ead65c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "nb_classes = len(classes)\n",
        "nb_classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "345"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfMoM-O3_c6I",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "##Load the Data\n",
        "Each class contains different number samples of arrays stored as .npy format. Since we have some memory limitations we only load 5000 images per class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKdUyr2oALDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We download the images, which have been saved as numpy arrays\n",
        "# NB: each file contains many images: it is an array of gray scale images, ie. an array of shape [nb_images, 28, 28, 1]\n",
        "# where each image is 28x28 pixels, gray scale.\n",
        "import urllib.request\n",
        "def download(class_file):\n",
        "  \n",
        "  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "  cls_url = class_file.replace(' ', '%20')\n",
        "  path = base+cls_url+'.npy'\n",
        "  print(path)\n",
        "  # We download the file in the directory 'data'\n",
        "  urllib.request.urlretrieve(path, DATA_DIRECTORY + '/'+class_file+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrVFomtncl1e",
        "colab_type": "code",
        "outputId": "0e51e181-0894-4632-ba6a-ff50363d41c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "classes[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Eiffel Tower'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHpkecv0Ab-Y",
        "colab_type": "code",
        "outputId": "86f6e92b-9b63-4385-a9e4-d43dd8c0cf99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test with the first class\n",
        "download(classes[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yALHyo3HScxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# As explained here: https://github.com/googlecreativelab/quickdraw-dataset#numpy-bitmaps-npy ,\n",
        "# this dataset contains 28x28 gray scale images\n",
        "IMG_SIZE = 28\n",
        "\n",
        "# The dataset is too big for the memory of the Colaboratory virtual machine.\n",
        "# Therefore, we load only the NB_EXAMPLES_BY_CLASS of each class\n",
        "NB_EXAMPLES_BY_CLASS = 1000\n",
        "\n",
        "TEST_RATIO = 0.10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wuuwz39A8-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "# Loads in memory max_items_per_class samples of the class classe, by starting at index start_index\n",
        "def load_class(classe, start_index = 0, max_items_per_class= None ):  \n",
        "  \n",
        "    #load each data file \n",
        "    data = np.load( os.path.join(DATA_DIRECTORY, classe + '.npy') )\n",
        "    stop_index = len(data)\n",
        "    if max_items_per_class is not None:\n",
        "        stop_index = min(stop_index, start_index + max_items_per_class)\n",
        "    # Take the subset of data starting at index start_index, stopping at index stop_index\n",
        "    # You could use array slicing\n",
        "    data = data[start_index:stop_index]\n",
        "\n",
        "    return data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OACAoECqJOQK",
        "colab_type": "code",
        "outputId": "f68999b1-e715-4a7d-daa2-a54f3a96aea8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test with the first class\n",
        "x_tmp_0 = load_class(classes[0], 0, max_items_per_class=NB_EXAMPLES_BY_CLASS)\n",
        "x_tmp_0[24].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(784,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brKEFNQHHYgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from random import randint\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show one random example of class class_file\n",
        "def show_one_random_image(x_train):\n",
        "  \n",
        "  # Select a random index in x_train\n",
        "  idx = randint(0, len(x_train))\n",
        "  # Visualize the image x_train[idx]\n",
        "  # As x_train[idx] is a vector of length 728, you first need to reshape it to a matrix of shape (IMG_SIZE,IMG_SIZE)\n",
        "  # After that, you could use plt.imshow() in order to visualize it\n",
        "  # YOUR CODE HERE \n",
        "  print(idx)\n",
        "  #x_train[idx] = x_train[idx].reshape(IMG_SIZE,IMG_SIZE)\n",
        "  print(x_train[idx].shape)\n",
        "  img = plt.imshow(x_train[idx].reshape(IMG_SIZE,IMG_SIZE))\n",
        "  plt.show()\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ0yqI83IzAa",
        "colab_type": "code",
        "outputId": "06481c05-b605-4c8e-fd65-e6355e92b693",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "# You should call this function several times. You will see that people are drawing things\n",
        "# on very different ways.\n",
        "# Therefore, this dataset is much more difficult than MNIST, where the images of the numbers \n",
        "# are quite similar.\n",
        "show_one_random_image(x_tmp_0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "846\n",
            "(784,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f99361cb400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9LbEq41oIxr",
        "colab_type": "text"
      },
      "source": [
        "Now that the above functions work, we can download the full dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq9_SQvPoHqi",
        "colab_type": "code",
        "outputId": "f95bb879-2aea-437d-8dc0-ea7564d092a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5813
        }
      },
      "source": [
        "\n",
        "# Now that the previous function are working, we download and convert the full dataset\n",
        "for idx, classe in enumerate(classes):\n",
        "  download(classe)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Great%20Wall%20of%20China.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Mona%20Lisa.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/aircraft%20carrier.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/alarm%20clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ambulance.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/angel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/animal%20migration.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/anvil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/arm.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/asparagus.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/axe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/backpack.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bandage.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/barn.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball%20bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/baseball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basket.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/basketball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bathtub.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beach.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/beard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bed.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bee.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/belt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bench.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bicycle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/binoculars.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/birthday%20cake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/blackberry.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/blueberry.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/boomerang.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bottlecap.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bowtie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bracelet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/brain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bread.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bridge.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broccoli.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bucket.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bulldozer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bus.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bush.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/butterfly.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cactus.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/calculator.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/calendar.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camera.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/camouflage.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/campfire.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cannon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/canoe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/carrot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/castle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ceiling%20fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cell%20phone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cello.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chair.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/chandelier.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/church.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clarinet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/clock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/coffee%20cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/compass.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/computer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cookie.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cooler.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/couch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crab.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crayon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crocodile.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/crown.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cruise%20ship.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cup.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diamond.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dishwasher.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/diving%20board.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dolphin.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/donut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/door.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dragon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dresser.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drill.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/drums.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/duck.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dumbbell.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ear.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/elbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/elephant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/envelope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eraser.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eye.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/eyeglasses.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/feather.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fence.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/finger.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fire%20hydrant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fireplace.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/firetruck.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fish.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flamingo.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flashlight.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flip%20flops.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/floor%20lamp.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flower.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/flying%20saucer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/foot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/fork.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/frying%20pan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/garden%20hose.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/garden.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/giraffe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/goatee.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/golf%20club.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grass.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/guitar.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hamburger.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hammer.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hand.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/harp.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/headphones.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hedgehog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helicopter.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/helmet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hexagon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hockey%20puck.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hockey%20stick.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/horse.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hospital.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20air%20balloon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20dog.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hot%20tub.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hourglass.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house%20plant.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/house.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/hurricane.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ice%20cream.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/jacket.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/jail.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/kangaroo.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/key.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/keyboard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knee.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/knife.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ladder.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lantern.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/laptop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/leaf.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/leg.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/light%20bulb.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lighter.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lighthouse.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lightning.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/line.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lion.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lipstick.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lobster.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/lollipop.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mailbox.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/map.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/marker.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/matches.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/megaphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mermaid.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microphone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/microwave.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/monkey.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mosquito.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/motorbike.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mountain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mouse.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/moustache.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mouth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mug.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/mushroom.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/nail.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/necklace.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/nose.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/ocean.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octagon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/octopus.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/onion.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/oven.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/owl.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paint%20can.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paintbrush.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/palm%20tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/panda.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pants.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/paper%20clip.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/parachute.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/parrot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/passport.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/peanut.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pear.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/peas.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pencil.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/penguin.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/piano.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pickup%20truck.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/picture%20frame.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pig.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pillow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pineapple.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pizza.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pliers.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/police%20car.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pond.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pool.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/popsicle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/postcard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/potato.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/power%20outlet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/purse.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rabbit.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/raccoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/radio.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rain.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rainbow.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/remote%20control.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rhinoceros.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rifle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/river.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/roller%20coaster.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/rollerskates.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sailboat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sandwich.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/saxophone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/school%20bus.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scissors.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/scorpion.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/screwdriver.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sea%20turtle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/see%20saw.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shark.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sheep.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shoe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shorts.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/shovel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sink.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/skateboard.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/skull.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/skyscraper.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sleeping%20bag.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/smiley%20face.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snail.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snorkel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snowflake.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/snowman.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/soccer%20ball.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sock.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/speedboat.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spider.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spoon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/spreadsheet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/square.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/squiggle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/squirrel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stairs.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/star.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/steak.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stereo.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stethoscope.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stitches.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stop%20sign.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/stove.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/strawberry.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/streetlight.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/string%20bean.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/submarine.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/suitcase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sun.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/swan.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sweater.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/swing%20set.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/sword.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/syringe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/t-shirt.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/table.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/teapot.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/teddy-bear.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/telephone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/television.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tennis%20racquet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tent.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tiger.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toaster.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toe.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toilet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tooth.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toothbrush.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/toothpaste.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tornado.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tractor.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/traffic%20light.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/train.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/tree.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/triangle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/trombone.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/truck.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/trumpet.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/umbrella.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/underwear.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/van.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/vase.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/violin.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/washing%20machine.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/watermelon.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/waterslide.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/whale.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wheel.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/windmill.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wine%20bottle.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wine%20glass.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/wristwatch.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/yoga.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zebra.npy\n",
            "https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/zigzag.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdoBpuq7U94f",
        "colab_type": "text"
      },
      "source": [
        "##Define the neural network\n",
        "\n",
        "Here is an architecture that works:\n",
        "- convolution2D, 16 filters of size 3x3, padding 'same', activation 'relu'\n",
        "- maxPool2D of size 2x2\n",
        "- convolution2D, 32 filters of size 3x3, padding 'same', activation 'relu'\n",
        "- maxPool2D of size 2x2\n",
        "- convolution2D, 64 filters of size 3x3, padding 'same', activation 'relu'\n",
        "- maxPool2D of size 2x2\n",
        "- dense layer with 1000 neurons, activation 'relu'\n",
        "- dense layer for the output\n",
        "\n",
        "   * Don't forget to flatten the output of the last maxpool layer, before the first dense layer\n",
        "\n",
        "HOW MANY NEURONS MUST THE LAST LAYER HAVE ?\n",
        "\n",
        "As we need to do classification over many classes:\n",
        "- which activation function must we use in the last layer ?\n",
        "- which loss function must we use ?\n",
        "\n",
        "USE THE METRIC top_k_categorical_accuracy INSTEAD OF THE USUAL accuracy. WHAT DOES THAT METRIC DO ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15dLKWu3VAaG",
        "colab_type": "code",
        "outputId": "fe549445-2a1c-4b04-9e97-8b9356961c1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "import keras as keras\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.layers.core import Flatten, Dense\n",
        "\n",
        "\n",
        "# Define model\n",
        "model = keras.Sequential()\n",
        "# YOUR CODE HERE\n",
        "model.add(Conv2D(16, (3, 3), padding=\"same\", input_shape=(28,28,1), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "          \n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())          \n",
        "model.add(Dense(1000, activation=\"relu\"))         \n",
        "\n",
        "model.add(Dense(345, activation=\"softmax\"))    \n",
        "          \n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"top_k_categorical_accuracy\"])          \n",
        "          \n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1000)              577000    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 345)               345345    \n",
            "=================================================================\n",
            "Total params: 945,641\n",
            "Trainable params: 945,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usmyWPzCYw_A",
        "colab_type": "text"
      },
      "source": [
        "##Train the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQJVjWJ1onpK",
        "colab_type": "text"
      },
      "source": [
        "Iterate over the classes and load them with load_class().\n",
        "Store the images in a array called x, and the labels in an array called y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V8nlszAofQy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def load_data(start_index = 0, max_items_per_class= None ):\n",
        "  \n",
        "  #initialize variables \n",
        "  x = np.empty([0, 784])\n",
        "  y = np.empty([0])\n",
        "\n",
        "  for idx, classe in enumerate(classes):\n",
        "    # Load max_items_per_class samples of the class classe, starting at start_index\n",
        "    data = load_class(classe, start_index = start_index, max_items_per_class= max_items_per_class)\n",
        "    # The label of this class is idx (the index of the class in the list of classes)\n",
        "    # As you need to label each sample of data, you have to create a vector of that size,\n",
        "    # filled with that label idx\n",
        "    labels = np.full(data.shape[0],idx)# YOUR CODE HERE. Hint: use np.full() in order to create a vector of size data.shape[0] that you fill with idx\n",
        "\n",
        "    x = np.concatenate((x, data), axis=0)\n",
        "    y = np.append(y, labels)\n",
        "    \n",
        "  \n",
        "  #randomize the dataset \n",
        "  permutation = np.random.permutation(y.shape[0])\n",
        "  x = x[permutation, :]\n",
        "  y = y[permutation]\n",
        "    \n",
        "  return x,y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcdwBIAapPJq",
        "colab_type": "text"
      },
      "source": [
        "Train the network into a loop which:\n",
        "- loads the next NB_EXAMPLES_BY_CLASS in memory\n",
        "- reshapes the images to [IMG_SIZE, IMG_SIZE, 1] arrays\n",
        "- normalizes the images\n",
        "- one-hot-encodes the labels\n",
        "- improves the training of the neural network on that subset\n",
        "\n",
        "You can limit the training to the first 20.000 samples of each class. According to my tests, the results improve very slightly if you add more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SPcHuXtXUVw",
        "colab_type": "code",
        "outputId": "98932ec9-8d42-4cc8-a2c2-ead093537d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2187
        }
      },
      "source": [
        "\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "\n",
        "stop_after_2_bad_epochs = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "for i in range(20000 // NB_EXAMPLES_BY_CLASS):\n",
        "    start_index = i * NB_EXAMPLES_BY_CLASS\n",
        "    print('Loading index ' + str(start_index) + '. Be patient, it will take a while before the training begins.')\n",
        "    # Load NB_EXAMPLES_BY_CLASS samples, starting at index start_index\n",
        "    x_train, y_train = load_data(start_index = start_index, max_items_per_class= NB_EXAMPLES_BY_CLASS) # YOUR CODE HERE\n",
        "    \n",
        "    # Reshape and normalize\n",
        "    x_train = x_train.reshape(x_train.shape[0], IMG_SIZE, IMG_SIZE, 1).astype('float32')\n",
        "\n",
        "    # What is the easiest way to normalize images ?\n",
        "    x_train = x_train/255# YOUR CODE HERE\n",
        "\n",
        "    # one-hot-encode y_train and y_test, using keras.utils.to_categorical()\n",
        "    y_train = keras.utils.to_categorical(y_train,nb_classes) # YOUR CODE HERE\n",
        "    #y_test = keras.utils.to_categorical(y_test,nb_classes)# YOUR CODE HERE\n",
        "    \n",
        "    # Launch the training by calling model.fit()\n",
        "    # Use validation_split=0.1 , so that 10% of the data will be used as a validation set\n",
        "    # Use a batch size of 256, 50 epochs, and the callback stop_after_2_bad_epochs in order to stop\n",
        "    # before overfitting\n",
        "    # YOUR CODE HERE\n",
        "    model.fit(x_train, y_train, validation_split=0.1, batch_size=256, epochs=50,verbose=1, callbacks=[EarlyStopping(monitor='val_loss', patience=2)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading index 0. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 275s 886us/step - loss: 2.9624 - top_k_categorical_accuracy: 0.6162 - val_loss: 2.2781 - val_top_k_categorical_accuracy: 0.7487\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 122s 394us/step - loss: 2.0532 - top_k_categorical_accuracy: 0.7830 - val_loss: 2.0090 - val_top_k_categorical_accuracy: 0.7920\n",
            "Epoch 3/50\n",
            "310500/310500 [==============================] - 107s 345us/step - loss: 1.7990 - top_k_categorical_accuracy: 0.8211 - val_loss: 1.9063 - val_top_k_categorical_accuracy: 0.8086\n",
            "Epoch 4/50\n",
            "310500/310500 [==============================] - 80s 259us/step - loss: 1.6387 - top_k_categorical_accuracy: 0.8425 - val_loss: 1.8572 - val_top_k_categorical_accuracy: 0.8153\n",
            "Epoch 5/50\n",
            "310500/310500 [==============================] - 82s 265us/step - loss: 1.5142 - top_k_categorical_accuracy: 0.8584 - val_loss: 1.8235 - val_top_k_categorical_accuracy: 0.8217\n",
            "Epoch 6/50\n",
            "310500/310500 [==============================] - 87s 281us/step - loss: 1.4109 - top_k_categorical_accuracy: 0.8717 - val_loss: 1.8335 - val_top_k_categorical_accuracy: 0.8207\n",
            "Loading index 1000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 69us/step - loss: 1.3767 - top_k_categorical_accuracy: 0.8767 - val_loss: 1.3864 - val_top_k_categorical_accuracy: 0.8759\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 65us/step - loss: 1.2833 - top_k_categorical_accuracy: 0.8881 - val_loss: 1.4541 - val_top_k_categorical_accuracy: 0.8687\n",
            "Loading index 2000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 1.2294 - top_k_categorical_accuracy: 0.8946 - val_loss: 1.3002 - val_top_k_categorical_accuracy: 0.8865\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 1.1494 - top_k_categorical_accuracy: 0.9039 - val_loss: 1.3869 - val_top_k_categorical_accuracy: 0.8758\n",
            "Loading index 3000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 20s 65us/step - loss: 1.1104 - top_k_categorical_accuracy: 0.9093 - val_loss: 1.1818 - val_top_k_categorical_accuracy: 0.9008\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 1.0375 - top_k_categorical_accuracy: 0.9178 - val_loss: 1.2951 - val_top_k_categorical_accuracy: 0.8871\n",
            "Loading index 4000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 1.0111 - top_k_categorical_accuracy: 0.9215 - val_loss: 1.0852 - val_top_k_categorical_accuracy: 0.9128\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 0.9442 - top_k_categorical_accuracy: 0.9291 - val_loss: 1.1876 - val_top_k_categorical_accuracy: 0.8999\n",
            "Loading index 5000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 20s 66us/step - loss: 0.9219 - top_k_categorical_accuracy: 0.9318 - val_loss: 0.9988 - val_top_k_categorical_accuracy: 0.9241\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 0.8579 - top_k_categorical_accuracy: 0.9389 - val_loss: 1.1123 - val_top_k_categorical_accuracy: 0.9116\n",
            "Loading index 6000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 20s 66us/step - loss: 0.8412 - top_k_categorical_accuracy: 0.9412 - val_loss: 0.9383 - val_top_k_categorical_accuracy: 0.9326\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 0.7828 - top_k_categorical_accuracy: 0.9474 - val_loss: 1.0588 - val_top_k_categorical_accuracy: 0.9212\n",
            "Loading index 7000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 69us/step - loss: 0.7726 - top_k_categorical_accuracy: 0.9488 - val_loss: 0.8690 - val_top_k_categorical_accuracy: 0.9406\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 66us/step - loss: 0.7151 - top_k_categorical_accuracy: 0.9547 - val_loss: 1.0014 - val_top_k_categorical_accuracy: 0.9270\n",
            "Loading index 8000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 0.7142 - top_k_categorical_accuracy: 0.9552 - val_loss: 0.8125 - val_top_k_categorical_accuracy: 0.9465\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 0.6624 - top_k_categorical_accuracy: 0.9604 - val_loss: 0.9221 - val_top_k_categorical_accuracy: 0.9379\n",
            "Loading index 9000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 22s 71us/step - loss: 0.6586 - top_k_categorical_accuracy: 0.9612 - val_loss: 0.7538 - val_top_k_categorical_accuracy: 0.9521\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 0.6038 - top_k_categorical_accuracy: 0.9658 - val_loss: 0.8885 - val_top_k_categorical_accuracy: 0.9408\n",
            "Loading index 10000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 0.6102 - top_k_categorical_accuracy: 0.9659 - val_loss: 0.7097 - val_top_k_categorical_accuracy: 0.9589\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 66us/step - loss: 0.5577 - top_k_categorical_accuracy: 0.9703 - val_loss: 0.8553 - val_top_k_categorical_accuracy: 0.9462\n",
            "Loading index 11000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 69us/step - loss: 0.5652 - top_k_categorical_accuracy: 0.9703 - val_loss: 0.6515 - val_top_k_categorical_accuracy: 0.9642\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 0.5172 - top_k_categorical_accuracy: 0.9741 - val_loss: 0.7939 - val_top_k_categorical_accuracy: 0.9518\n",
            "Loading index 12000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 28s 91us/step - loss: 0.5306 - top_k_categorical_accuracy: 0.9738 - val_loss: 0.6334 - val_top_k_categorical_accuracy: 0.9661\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 66us/step - loss: 0.4776 - top_k_categorical_accuracy: 0.9776 - val_loss: 0.7750 - val_top_k_categorical_accuracy: 0.9571\n",
            "Loading index 13000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 0.4926 - top_k_categorical_accuracy: 0.9771 - val_loss: 0.5839 - val_top_k_categorical_accuracy: 0.9710\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 66us/step - loss: 0.4450 - top_k_categorical_accuracy: 0.9801 - val_loss: 0.7223 - val_top_k_categorical_accuracy: 0.9613\n",
            "Loading index 14000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 0.4623 - top_k_categorical_accuracy: 0.9797 - val_loss: 0.5413 - val_top_k_categorical_accuracy: 0.9744\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 0.4181 - top_k_categorical_accuracy: 0.9827 - val_loss: 0.6777 - val_top_k_categorical_accuracy: 0.9654\n",
            "Loading index 15000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 0.4355 - top_k_categorical_accuracy: 0.9822 - val_loss: 0.5183 - val_top_k_categorical_accuracy: 0.9768\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 0.3916 - top_k_categorical_accuracy: 0.9847 - val_loss: 0.6567 - val_top_k_categorical_accuracy: 0.9684\n",
            "Loading index 16000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 0.4084 - top_k_categorical_accuracy: 0.9841 - val_loss: 0.4855 - val_top_k_categorical_accuracy: 0.9806\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 64us/step - loss: 0.3719 - top_k_categorical_accuracy: 0.9866 - val_loss: 0.5881 - val_top_k_categorical_accuracy: 0.9743\n",
            "Loading index 17000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 69us/step - loss: 0.3896 - top_k_categorical_accuracy: 0.9856 - val_loss: 0.4470 - val_top_k_categorical_accuracy: 0.9823\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 21s 67us/step - loss: 0.3431 - top_k_categorical_accuracy: 0.9881 - val_loss: 0.6144 - val_top_k_categorical_accuracy: 0.9745\n",
            "Loading index 18000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 21s 68us/step - loss: 0.3687 - top_k_categorical_accuracy: 0.9870 - val_loss: 0.4526 - val_top_k_categorical_accuracy: 0.9837\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 20s 66us/step - loss: 0.3297 - top_k_categorical_accuracy: 0.9893 - val_loss: 0.5661 - val_top_k_categorical_accuracy: 0.9766\n",
            "Loading index 19000. Be patient, it will take a while before the training begins.\n",
            "Train on 310500 samples, validate on 34500 samples\n",
            "Epoch 1/50\n",
            "310500/310500 [==============================] - 23s 73us/step - loss: 0.3509 - top_k_categorical_accuracy: 0.9885 - val_loss: 0.4109 - val_top_k_categorical_accuracy: 0.9868\n",
            "Epoch 2/50\n",
            "310500/310500 [==============================] - 22s 70us/step - loss: 0.3118 - top_k_categorical_accuracy: 0.9904 - val_loss: 0.5410 - val_top_k_categorical_accuracy: 0.9792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65rraDvT7-Ey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save( 'DL-TP2.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aP0fMF6FZJvi",
        "colab_type": "text"
      },
      "source": [
        "##Prepare the application for your smartphone\n",
        "We convert the model to a JSON file compatible with TensorFlowJS\n",
        "\n",
        "![Texte alternatif…](https://cdn-images-1.medium.com/max/800/1*i2S-d3c-NcFxCnUhNd_Wfg.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvX4Z99Jh6Do",
        "colab_type": "code",
        "outputId": "8daa34b7-45b8-47bb-d4ee-fb0768892f35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget http://www.eyrignoux.com.fr/coursIA/deepLearning/DL-TP2.h5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-11-29 00:14:45--  http://www.eyrignoux.com.fr/coursIA/deepLearning/DL-TP2.h5\n",
            "Resolving www.eyrignoux.com.fr (www.eyrignoux.com.fr)... 62.210.16.62\n",
            "Connecting to www.eyrignoux.com.fr (www.eyrignoux.com.fr)|62.210.16.62|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11393776 (11M)\n",
            "Saving to: ‘DL-TP2.h5.1’\n",
            "\n",
            "\rDL-TP2.h5.1           0%[                    ]       0  --.-KB/s               \rDL-TP2.h5.1           0%[                    ]  50.21K   246KB/s               \rDL-TP2.h5.1           1%[                    ] 217.07K   533KB/s               \rDL-TP2.h5.1           7%[>                   ] 872.26K  1.39MB/s               \rDL-TP2.h5.1          31%[=====>              ]   3.44M  4.22MB/s               \rDL-TP2.h5.1          86%[================>   ]   9.40M  9.23MB/s               \rDL-TP2.h5.1         100%[===================>]  10.87M  10.5MB/s    in 1.0s    \n",
            "\n",
            "2018-11-29 00:14:47 (10.5 MB/s) - ‘DL-TP2.h5.1’ saved [11393776/11393776]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPTW-ax9vW1R",
        "colab_type": "code",
        "outputId": "8e8eb862-f9c5-49c1-bf57-ed32fe880aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "!git clone https://github.com/zaidalyafeai/zaidalyafeai.github.io.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'zaidalyafeai.github.io'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/61)   \u001b[K\rremote: Counting objects:   3% (2/61)   \u001b[K\rremote: Counting objects:   4% (3/61)   \u001b[K\rremote: Counting objects:   6% (4/61)   \u001b[K\rremote: Counting objects:   8% (5/61)   \u001b[K\rremote: Counting objects:   9% (6/61)   \u001b[K\rremote: Counting objects:  11% (7/61)   \u001b[K\rremote: Counting objects:  13% (8/61)   \u001b[K\rremote: Counting objects:  14% (9/61)   \u001b[K\rremote: Counting objects:  16% (10/61)   \u001b[K\rremote: Counting objects:  18% (11/61)   \u001b[K\rremote: Counting objects:  19% (12/61)   \u001b[K\rremote: Counting objects:  21% (13/61)   \u001b[K\rremote: Counting objects:  22% (14/61)   \u001b[K\rremote: Counting objects:  24% (15/61)   \u001b[K\rremote: Counting objects:  26% (16/61)   \u001b[K\rremote: Counting objects:  27% (17/61)   \u001b[K\rremote: Counting objects:  29% (18/61)   \u001b[K\rremote: Counting objects:  31% (19/61)   \u001b[K\rremote: Counting objects:  32% (20/61)   \u001b[K\rremote: Counting objects:  34% (21/61)   \u001b[K\rremote: Counting objects:  36% (22/61)   \u001b[K\rremote: Counting objects:  37% (23/61)   \u001b[K\rremote: Counting objects:  39% (24/61)   \u001b[K\rremote: Counting objects:  40% (25/61)   \u001b[K\rremote: Counting objects:  42% (26/61)   \u001b[K\rremote: Counting objects:  44% (27/61)   \u001b[K\rremote: Counting objects:  45% (28/61)   \u001b[K\rremote: Counting objects:  47% (29/61)   \u001b[K\rremote: Counting objects:  49% (30/61)   \u001b[K\rremote: Counting objects:  50% (31/61)   \u001b[K\rremote: Counting objects:  52% (32/61)   \u001b[K\rremote: Counting objects:  54% (33/61)   \u001b[K\rremote: Counting objects:  55% (34/61)   \u001b[K\rremote: Counting objects:  57% (35/61)   \u001b[K\rremote: Counting objects:  59% (36/61)   \u001b[K\rremote: Counting objects:  60% (37/61)   \u001b[K\rremote: Counting objects:  62% (38/61)   \u001b[K\rremote: Counting objects:  63% (39/61)   \u001b[K\rremote: Counting objects:  65% (40/61)   \u001b[K\rremote: Counting objects:  67% (41/61)   \u001b[K\rremote: Counting objects:  68% (42/61)   \u001b[K\rremote: Counting objects:  70% (43/61)   \u001b[K\rremote: Counting objects:  72% (44/61)   \u001b[K\rremote: Counting objects:  73% (45/61)   \u001b[K\rremote: Counting objects:  75% (46/61)   \u001b[K\rremote: Counting objects:  77% (47/61)   \u001b[K\rremote: Counting objects:  78% (48/61)   \u001b[K\rremote: Counting objects:  80% (49/61)   \u001b[K\rremote: Counting objects:  81% (50/61)   \u001b[K\rremote: Counting objects:  83% (51/61)   \u001b[K\rremote: Counting objects:  85% (52/61)   \u001b[K\rremote: Counting objects:  86% (53/61)   \u001b[K\rremote: Counting objects:  88% (54/61)   \u001b[K\rremote: Counting objects:  90% (55/61)   \u001b[K\rremote: Counting objects:  91% (56/61)   \u001b[K\rremote: Counting objects:  93% (57/61)   \u001b[K\rremote: Counting objects:  95% (58/61)   \u001b[K\rremote: Counting objects:  96% (59/61)   \u001b[K\rremote: Counting objects:  98% (60/61)   \u001b[K\rremote: Counting objects: 100% (61/61)   \u001b[K\rremote: Counting objects: 100% (61/61), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 6997 (delta 33), reused 0 (delta 0), pack-reused 6936\u001b[K\n",
            "Receiving objects: 100% (6997/6997), 2.01 GiB | 28.48 MiB/s, done.\n",
            "Resolving deltas: 100% (3433/3433), done.\n",
            "Checking out files: 100% (771/771), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JpGVItFvl0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "WEB_DIRECTORY = \"/content/zaidalyafeai.github.io/sketcher\"\n",
        "MODEL_WEB_DIRECTORY = WEB_DIRECTORY + \"/model2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfGmTx4Up9PR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm {MODEL_WEB_DIRECTORY + \"/*\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MkL5DjeZTDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open( MODEL_WEB_DIRECTORY + '/class_names.txt', 'w') as file_handler:\n",
        "    for item in classes:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqG_3OUoZe3x",
        "colab_type": "code",
        "outputId": "2dd18c7d-7472-4a8b-9598-008def765a63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading https://files.pythonhosted.org/packages/8c/d3/f534d1d042465e0e66a04b0fa31dc1f13cfea7d8340017ef4cd649b9c3a0/tensorflowjs-0.6.7-py3-none-any.whl\n",
            "Collecting keras==2.2.2 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
            "\r\u001b[K    3% |█                               | 10kB 6.5MB/s eta 0:00:01\r\u001b[K    6% |██▏                             | 20kB 5.7MB/s eta 0:00:01\r\u001b[K    10% |███▎                            | 30kB 5.4MB/s eta 0:00:01\r\u001b[K    13% |████▍                           | 40kB 4.3MB/s eta 0:00:01\r\u001b[K    17% |█████▌                          | 51kB 3.9MB/s eta 0:00:01\r\u001b[K    20% |██████▋                         | 61kB 4.6MB/s eta 0:00:01\r\u001b[K    23% |███████▋                        | 71kB 4.2MB/s eta 0:00:01\r\u001b[K    27% |████████▊                       | 81kB 3.9MB/s eta 0:00:01\r\u001b[K    30% |█████████▉                      | 92kB 4.4MB/s eta 0:00:01\r\u001b[K    34% |███████████                     | 102kB 4.3MB/s eta 0:00:01\r\u001b[K    37% |████████████                    | 112kB 4.5MB/s eta 0:00:01\r\u001b[K    41% |█████████████▏                  | 122kB 4.2MB/s eta 0:00:01\r\u001b[K    44% |██████████████▎                 | 133kB 4.0MB/s eta 0:00:01\r\u001b[K    47% |███████████████▎                | 143kB 4.7MB/s eta 0:00:01\r\u001b[K    51% |████████████████▍               | 153kB 5.1MB/s eta 0:00:01\r\u001b[K    54% |█████████████████▌              | 163kB 4.3MB/s eta 0:00:01\r\u001b[K    58% |██████████████████▋             | 174kB 5.0MB/s eta 0:00:01\r\u001b[K    61% |███████████████████▊            | 184kB 5.4MB/s eta 0:00:01\r\u001b[K    65% |████████████████████▉           | 194kB 5.4MB/s eta 0:00:01\r\u001b[K    68% |██████████████████████          | 204kB 5.2MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 215kB 4.6MB/s eta 0:00:01\r\u001b[K    75% |████████████████████████        | 225kB 5.4MB/s eta 0:00:01\r\u001b[K    78% |█████████████████████████▏      | 235kB 5.6MB/s eta 0:00:01\r\u001b[K    82% |██████████████████████████▎     | 245kB 4.9MB/s eta 0:00:01\r\u001b[K    85% |███████████████████████████▍    | 256kB 5.4MB/s eta 0:00:01\r\u001b[K    88% |████████████████████████████▌   | 266kB 5.2MB/s eta 0:00:01\r\u001b[K    92% |█████████████████████████████▋  | 276kB 5.2MB/s eta 0:00:01\r\u001b[K    95% |██████████████████████████████▋ | 286kB 5.3MB/s eta 0:00:01\r\u001b[K    99% |███████████████████████████████▊| 296kB 5.1MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 307kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow==1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: h5py==2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.8.0)\n",
            "Collecting numpy==1.15.1 (from tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/94/7049fed8373c52839c8cde619acaf2c9b83082b935e5aa8c0fa27a4a8bcc/numpy-1.15.1-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
            "\u001b[K    100% |████████████████████████████████| 13.9MB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub==0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (0.1.1)\n",
            "Requirement already satisfied: six==1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (3.13)\n",
            "Collecting keras-applications==1.0.4 (from keras==2.2.2->tensorflowjs)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.2->tensorflowjs) (1.1.0)\n",
            "Collecting keras-preprocessing==1.0.2 (from keras==2.2.2->tensorflowjs)\n",
            "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (3.6.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.32.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0->tensorflowjs) (40.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (3.0.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0->tensorflowjs) (0.14.1)\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-applications>=1.0.6, but you'll have keras-applications 1.0.4 which is incompatible.\u001b[0m\n",
            "\u001b[31mtensorflow 1.12.0 has requirement keras-preprocessing>=1.0.5, but you'll have keras-preprocessing 1.0.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-applications, keras-preprocessing, keras, tensorflowjs\n",
            "  Found existing installation: numpy 1.14.6\n",
            "    Uninstalling numpy-1.14.6:\n",
            "      Successfully uninstalled numpy-1.14.6\n",
            "  Found existing installation: Keras-Applications 1.0.6\n",
            "    Uninstalling Keras-Applications-1.0.6:\n",
            "      Successfully uninstalled Keras-Applications-1.0.6\n",
            "  Found existing installation: Keras-Preprocessing 1.0.5\n",
            "    Uninstalling Keras-Preprocessing-1.0.5:\n",
            "      Successfully uninstalled Keras-Preprocessing-1.0.5\n",
            "  Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "Successfully installed keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 numpy-1.15.1 tensorflowjs-0.6.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pch-ryQqZ9Wg",
        "colab_type": "code",
        "outputId": "fd1dd79d-c204-4479-9080-6b483b25060c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "!tensorflowjs_converter --input_format keras DL-TP2.h5 {MODEL_WEB_DIRECTORY + \"/\"}"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSvRrFVkylKy",
        "colab_type": "text"
      },
      "source": [
        "##Open a http tunnel so that you can reach the web application from your smartphone\n",
        "We are going to start a HTTP server inside the VM, but it won't be visible from outside.\n",
        "\n",
        "Therefore, we first need to open a tunnel that you can call with your smartphone or any other device.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qczAWgni8NpY",
        "colab_type": "code",
        "outputId": "b3e6fcaf-a8fc-4759-9dc2-3031c3c39778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!git clone https://github.com/mixuala/colab_utils.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'colab_utils'...\n",
            "remote: Enumerating objects: 243, done.\u001b[K\n",
            "Receiving objects:   0% (1/243)   \rReceiving objects:   1% (3/243)   \rReceiving objects:   2% (5/243)   \rReceiving objects:   3% (8/243)   \rReceiving objects:   4% (10/243)   \rReceiving objects:   5% (13/243)   \rReceiving objects:   6% (15/243)   \rReceiving objects:   7% (18/243)   \rReceiving objects:   8% (20/243)   \rReceiving objects:   9% (22/243)   \rReceiving objects:  10% (25/243)   \rReceiving objects:  11% (27/243)   \rReceiving objects:  12% (30/243)   \rReceiving objects:  13% (32/243)   \rReceiving objects:  14% (35/243)   \rReceiving objects:  15% (37/243)   \rReceiving objects:  16% (39/243)   \rReceiving objects:  17% (42/243)   \rReceiving objects:  18% (44/243)   \rReceiving objects:  19% (47/243)   \rReceiving objects:  20% (49/243)   \rReceiving objects:  21% (52/243)   \rReceiving objects:  22% (54/243)   \rReceiving objects:  23% (56/243)   \rReceiving objects:  24% (59/243)   \rReceiving objects:  25% (61/243)   \rReceiving objects:  26% (64/243)   \rReceiving objects:  27% (66/243)   \rReceiving objects:  28% (69/243)   \rReceiving objects:  29% (71/243)   \rReceiving objects:  30% (73/243)   \rReceiving objects:  31% (76/243)   \rReceiving objects:  32% (78/243)   \rReceiving objects:  33% (81/243)   \rReceiving objects:  34% (83/243)   \rReceiving objects:  35% (86/243)   \rReceiving objects:  36% (88/243)   \rReceiving objects:  37% (90/243)   \rReceiving objects:  38% (93/243)   \rReceiving objects:  39% (95/243)   \rReceiving objects:  40% (98/243)   \rReceiving objects:  41% (100/243)   \rReceiving objects:  42% (103/243)   \rReceiving objects:  43% (105/243)   \rReceiving objects:  44% (107/243)   \rReceiving objects:  45% (110/243)   \rReceiving objects:  46% (112/243)   \rReceiving objects:  47% (115/243)   \rReceiving objects:  48% (117/243)   \rReceiving objects:  49% (120/243)   \rReceiving objects:  50% (122/243)   \rReceiving objects:  51% (124/243)   \rReceiving objects:  52% (127/243)   \rReceiving objects:  53% (129/243)   \rReceiving objects:  54% (132/243)   \rReceiving objects:  55% (134/243)   \rReceiving objects:  56% (137/243)   \rReceiving objects:  57% (139/243)   \rReceiving objects:  58% (141/243)   \rReceiving objects:  59% (144/243)   \rReceiving objects:  60% (146/243)   \rReceiving objects:  61% (149/243)   \rReceiving objects:  62% (151/243)   \rReceiving objects:  63% (154/243)   \rReceiving objects:  64% (156/243)   \rReceiving objects:  65% (158/243)   \rReceiving objects:  66% (161/243)   \rReceiving objects:  67% (163/243)   \rReceiving objects:  68% (166/243)   \rReceiving objects:  69% (168/243)   \rReceiving objects:  70% (171/243)   \rReceiving objects:  71% (173/243)   \rReceiving objects:  72% (175/243)   \rReceiving objects:  73% (178/243)   \rReceiving objects:  74% (180/243)   \rReceiving objects:  75% (183/243)   \rReceiving objects:  76% (185/243)   \rReceiving objects:  77% (188/243)   \rReceiving objects:  78% (190/243)   \rReceiving objects:  79% (192/243)   \rReceiving objects:  80% (195/243)   \rReceiving objects:  81% (197/243)   \rReceiving objects:  82% (200/243)   \rReceiving objects:  83% (202/243)   \rReceiving objects:  84% (205/243)   \rReceiving objects:  85% (207/243)   \rremote: Total 243 (delta 0), reused 0 (delta 0), pack-reused 243\u001b[K\n",
            "Receiving objects:  86% (209/243)   \rReceiving objects:  87% (212/243)   \rReceiving objects:  88% (214/243)   \rReceiving objects:  89% (217/243)   \rReceiving objects:  90% (219/243)   \rReceiving objects:  91% (222/243)   \rReceiving objects:  92% (224/243)   \rReceiving objects:  93% (226/243)   \rReceiving objects:  94% (229/243)   \rReceiving objects:  95% (231/243)   \rReceiving objects:  96% (234/243)   \rReceiving objects:  97% (236/243)   \rReceiving objects:  98% (239/243)   \rReceiving objects:  99% (241/243)   \rReceiving objects: 100% (243/243)   \rReceiving objects: 100% (243/243), 65.93 KiB | 1.40 MiB/s, done.\n",
            "Resolving deltas:   0% (0/97)   \rResolving deltas:   1% (1/97)   \rResolving deltas:   3% (3/97)   \rResolving deltas:   7% (7/97)   \rResolving deltas:  13% (13/97)   \rResolving deltas:  14% (14/97)   \rResolving deltas:  27% (27/97)   \rResolving deltas:  28% (28/97)   \rResolving deltas:  31% (31/97)   \rResolving deltas:  52% (51/97)   \rResolving deltas:  57% (56/97)   \rResolving deltas:  59% (58/97)   \rResolving deltas: 100% (97/97)   \rResolving deltas: 100% (97/97), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erI6p5r0wduX",
        "colab_type": "code",
        "outputId": "b21f35fd-2d9b-4610-8e97-56dca4ba87e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "\n",
        "import colab_utils.tboard\n",
        "\n",
        "DIR_GROK = '/content/tmp'\n",
        "!mkdir {DIR_GROK}\n",
        "colab_utils.tboard.install_ngrok(DIR_GROK)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/content/tmp’: File exists\n",
            "ngrok installed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Tz8GlyxQso",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HTTP_PORT = 8081\n",
        "get_ipython().system_raw('{}/ngrok http {} &'.format(DIR_GROK, HTTP_PORT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4s4puSgxoNf",
        "colab_type": "code",
        "outputId": "d3d08d04-4a45-43c3-e66e-e78632654fd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# get webapp url\n",
        "# BUG: getting connection refused for HTTPConnectionPool(host='localhost', port=4040)\n",
        "#     on first run, retry works\n",
        "import time\n",
        "import requests \n",
        "\n",
        "time.sleep(3)\n",
        "retval = requests.get('http://localhost:4040/api/tunnels')\n",
        "webapp_url = retval.json()['tunnels'][0]['public_url'].strip()\n",
        "print(\"webapp url=\", webapp_url)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "webapp url= http://ca0b8035.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-zXV2ZD8XCS",
        "colab_type": "text"
      },
      "source": [
        "##Start the web server\n",
        "WARNING: if you stop it, the VM gets killed as well, and you have to restart it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5QRuKJc8YMh",
        "colab_type": "code",
        "outputId": "dd966451-e043-44e9-d682-5ab8f41d8915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "import http.server\n",
        "import socketserver\n",
        "import os\n",
        "\n",
        "os.chdir(WEB_DIRECTORY)\n",
        "\n",
        "Handler = http.server.SimpleHTTPRequestHandler\n",
        "\n",
        "with socketserver.TCPServer((\"\", HTTP_PORT), Handler) as httpd:\n",
        "    print(\"serving at port\", HTTP_PORT)\n",
        "    httpd.serve_forever()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "serving at port 8081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [29/Nov/2018 00:26:27] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:27] \"GET /pie.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:27] \"GET /main.css HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:27] \"GET /fabric.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:28] \"GET /main.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:28] \"GET /pie.js HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:29] \"GET /model2/model.json HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:29] \"GET /model2/group1-shard1of1 HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:30] code 404, message File not found\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:30] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
            "127.0.0.1 - - [29/Nov/2018 00:26:31] \"GET /model2/class_names.txt HTTP/1.1\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}